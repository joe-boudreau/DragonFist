\section{Future Research} \label{s:futureresearch}
Based off the empirical results observed thus far it is clear that image transformations yield beneficial properties for image classification models in both adversarial resilience and model accuracy.
The models and filters implemented as part of these experiments achieved some level of success, but it is likely that further optimizations could still be achieved.
In particular, looking at different underlying model structures would be interesting.
Furthermore, researching the effects of adding Dropout and other regularization features to the models which would promote better generalization, a key feature for improving adversarial robustness could be beneficial.
Also, it seems likely that different filtered versions of images would require different model structures to fully optimize each individual model's accuracy.

In regards to filters specifically, much more investigation is needed to fully explore the space of filters and which ones are the most conducive to machine learning.
An interesting project would be to build a full filter testing framework to facilitate rigorous searching for effective filters and filter combinations, possibly boosted by an adaptive learning algorithm as well to reduce the search scope.

For the ensembling stage (FIST), there could be more effective training methods, such as bagging and boosting, which introduce variability into the training sets for each individual model and promote a less consistent response across the collection of models.
Intuitively, this should be beneficial for adversarial resilience because not every model would be susceptible to any particular adversarial image, due to their response diversity.

Finally, investigation into how well the DRAGONFIST design performs on higher resolution image sets would be a logical next step for this research as effectiveness at that level of complexity would be a more practical result, with implications for real-world machine learning applications.
