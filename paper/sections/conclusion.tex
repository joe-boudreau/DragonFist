\section{Conclusion} \label{s:conclusion}
	This paper has examined the effects of applying transformations to images when creating classification neural networks. We investigated the transferability to white-box adversarial images to models trained on filtered versions of said images as well as ensemble models containing multiple different filters. It was determined that DRAGONFIST is less effective against Fast Gradient Method white-box attacks when compared to Jacobian-based Saliency Map white-box attacks where a significant improvement was observed. Furthermore, a significant improvement against black-box attacks was also observed. DRAGONFIST can be applied to any model structure and is a step forward in improving a machine learning algorithm's ablity to mitigate adversarial noise.
