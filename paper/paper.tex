\documentclass[11pt,twocolumn]{IEEEtran}

\usepackage[numbers]{natbib}
\usepackage{multicol}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{xparse}

\NewDocumentCommand{\codeword}{v}{
	\texttt{\textcolor{blue}{#1}}
}

\renewcommand*{\bibfont}{\raggedright}

\setlength{\multicolsep}{6.0pt plus 2.0pt minus 1.5pt}

\title{DRAGONFIST}
\author{Joseph Boudreau, Andrew Ferrazzutti, Kia Shakiba, Zhongyu Zhao}
\date{December 9\textsuperscript{th}, 2018}

\begin{document}

	\maketitle

	\begin{abstract}
		The purpose of this paper is to examine the effects of applying transformations to images in the context of image classification neural networks.
		We investigate how using filtered images during training and inference affects the classification accuracy and resilience to adversarial attacks.
		The rationale supporting this methodology is that transforming the input images should obstruct or diffuse the intended perturbations of an adversarial example, while still preserving the significant features of the image so the model can effectively generalize and classify.
		Our findings indicate a marginal increase in both accuracy and a significant improvement in adversarial robustness for the ensemble model against black-box attacks and white-box attacks.
		Despite the improvement in accuracy, adversarial images are still misclassified \>50\% of the time in most cases, so this model structure cannot be considered completely effective at this time.
	\end{abstract}

	\input{sections/introduction.tex}
	\input{sections/terminology.tex}
    \input{sections/filters.tex}
	\input{sections/whiteboxattacks.tex}
	\input{sections/blackboxattacks.tex}
	\input{sections/futureresearch.tex}
	\input{sections/conclusion.tex}

	%\input{sections/appendix.tex}

	% ----- REFERENCES -----
	\bibliographystyle{IEEEtranN}
	\bibliography{references}{}

\end{document}
